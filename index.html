<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Xuanyu Yi&#39;s home page">
  <meta name="keywords" content="易炫宇, Xuanyu Yi" />
  
  <link href="./imgs/tlzdoc.css" rel="stylesheet" type="text/css">
</head>
<body>
  <div id="layout-content" style="margin-top: 25px;">
  
  <table>
    <tbody>
      <tr>
	<!--      基本信息		-->
        <td width="670">
          <div id="toptitle">
            <h1>Xuanyu Yi &nbsp; 易炫宇</h1>
          </div>
	  <h3>Ph.D. Candidate @ <a href="https://www.ntu.edu.sg/" target="_blank">Nanyang Technological University</a></h3>
	  <p>
                Address: 50 Nanyang Ave, 639798, Singapore <br>
                Email: xuanyu001@e.ntu.edu.sg or xuanyucver@gmail.com<br>
          </p>
	  <h3 style="padding-top:-5px"></h3>
          <!--      google  scholar		-->
	  <img src="./assets/googlescholar.png" width="16" height="16" style="margin-bottom:-3px">
          <a href="https://scholar.google.com/citations?user=91i3wqgAAAAJ&hl=zh-CN#">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <!--      semantic scholar		-->
	  <img src="./assets/semanticscholar.png" width="17" height="17" style="margin-bottom:-3px">
          <a href="https://www.semanticscholar.org/author/Xuanyu-Yi/2072766550">Semantic Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          <!--      dblp		-->
	  <img src="./assets/cv.png" width="15" height="15" style="margin-bottom:-3px">
          <a href="xxx.pdf">CV</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <!--      github		-->
	  <img src="./assets/github.jpg" width="16" height="16" style="margin-bottom:-3px">
          <a href="https://github.com/yxymessi">Github</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</td>
	<!--      头像		-->      
	<td>
          <img src="./imgs/Xuying.png" border="0" width="220">
        </td>
      </tr>    
    </tbody>
  </table>
	  
  <!--      个人简介		-->
  <h2>Biography<a name="biography"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <p style="text-indent:2em;"> 
    I am currently a Ph.D. candidate in <a href="https://mreallab.github.io/index.html#experience" target="_blank">Mreal Lab</a> @ NTU, advised by <a href="https://personal.ntu.edu.sg/hanwangzhang/" target="_blank">Prof. Hanwang Zhang</a>. I am also served as a research scholar in <a href="https://www.a-star.edu.sg/i2r" target="_blank">I<sup>2</sup>R, A<sup>*</sup>STAR</a>, advised by <a href="https://www.a-star.edu.sg/i2r/about-i2r/i2r-management/lim-joo-hwee" target="_blank">Prof. Lim Joo Hwee</a> . Before that, I received my Bachelor's degree from <a href="https://www.tsinghua.edu.cn/en/" target="_blank">Tsinghua University</a>, supervised by <a href="http://web.ee.tsinghua.edu.cn/wuji/zh_CN/index.htm" target="_blank">Prof. Ji Wu </a> and closely collabrated with <a href="http://www.slrss.cn/sourcedb_slrss_cas/kydw/ys/202008/t20200820_575915.html" target="_blank">Prof. Yirong Wu</a> and <a href="https://www.ccmu.edu.cn/pub/ccmu/rczy_6468/jcrc_13876/gjjrcxm_7903/gjbqwrcgc_12007/hdm_14253/index.html" target="_blank">Prof. Demin Han</a> . The outline of my experience is as follows:
  </p>
  <ul>  
     <li> 01/2024 -- Present: Research Intern, <a href="https://www.kunlun.com/research/" target="_blank">2050 Research</a>, Skywork AI, Singapore. </li>
    <li> 08/2023 -- 12/2023: Research Intern, <a href="https://sail.sea.com/" target="_blank">SEA AI Lab</a>, Singapore. </li> 
       <li> 09/2021 -- Present: Ph.D. Student in Computer Science, <a href="https://www.ntu.edu.sg/" target="_blank">Nanyang Technological University</a>, Singapre. </li> 
    <li> 06/2020 -- 11/2020: B.S. in Computer Science, Exchange Program @ <a href="https://www.usc.edu/" target="_blank">University of Southern California</a>,  Los Angeles, America. </li>
    <li> 08/2017 -- 07/2021: B.S. in Electronic Engineering, <a href="https://www.tsinghua.edu.cn/en/" target="_blank">Tsinghua University</a>, Beijng, China. </li>
  </ul>
  <!--	  
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <img src="imgs/NKU.png" width="88px" height="88px" alt=" /"></td>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <img src="imgs/XMU.png" width="88px" height="88px" alt=" /"></td>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <img src="imgs/JD.png" width="88px" height="88px" alt=" /"></td>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <img src="imgs/Hebut.png" width="88px" height="88px" alt=" /"></td>
  -->
  <p style="text-indent:2em;">
    My research interests include representation learning, Generative Model and 3D Vision. More recently, I focus on the following aspects:
    <ul> 
	 <li> Multimodal debiased learning, especially on vision and language. </li>  
	 <li> 3D understanding, reconstruction, generation and editting, especially on 3D scene generation. </li> 
         <li> 3DGS-based video generation model. </li> 
         <li> Anything about world model, real-world simulation. </li> 
    </ul> 
     &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<b>I’m graduating around Jul. 2025 and open to discussions on employment opportunities in Singapore, Europe and Shanghai</b>.
  </p>

  <!--      最新讯息		-->
  <h2>Latest News<a name="news"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <ul> 
    <li> 07/2024: Two paper were accepted by ECCV 2024. </li>
    <li> 02/2024: Two paper were accepted by CVPR 2024. </li>
    <li> 09/2023: One paper was accepted by ICCV 2023. </li>  
    <li> 10/2022: One paper was accepted by ECCV 2022 as <b>oral</b> presentation. </li>
  </ul>

  <!--      学术产出		-->
  <h2>Publication<a name="publications"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>

	  

	

  <!--      会议论文		-->
  <h3>Conference</h3>
  <table class="pub_table">
    <tbody>
      <tr>
       <td class="pub_td1">06<img src="./imgs/SAQA.png" class="papericon"></td>
       <td class="pub_td2"> Zheng Lin, Zheng-Peng Duan, <font color="goldenrod">Xuying Zhang</font>, Luojun Lin  
        <br><b>No-Reference Segmentation Annotation Quality Assessment</b>
        <br>IEEE International Conference on Multimedia and Expo (ICME), 2024, Oral, CCF-B
        <br>
        [<a href="https://arxiv.org/pdf/2312.04248.pdf" target="_blank">Paper Coming</a>]  
        [<a href="https://github.com/zhangxuying1004/TeMO" target="_blank">Code Coming</a>]
	[<a href="bibs/temo.html", target="_blank">BibTex</a>]
       </td>
     </tr>
	    
      <tr>
       <td class="pub_td1">05<img src="./imgs/TeMO.png" class="papericon"></td>
       <td class="pub_td2"> <font color="goldenrod">Xuying Zhang</font>, Bowen Yin, Yuming Chen, Zheng Lin, Yunheng Li, Qibin Hou<sup>✉</sup>, Ming-Ming Cheng
        <br><b>TeMO: Towards Text-Driven 3D Stylization for Multi-Object Meshes</b>
        <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024, CCF-A
        <br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_TeMO_Towards_Text-Driven_3D_Stylization_for_Multi-Object_Meshes_CVPR_2024_paper.pdf" target="_blank">Paper</a>]  
        [<a href="https://github.com/zhangxuying1004/TeMO" target="_blank">Code (<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhangxuying1004/TeMO?label=%F0%9F%8C%9F%20Star&color=blue">)</a>]
	[<a href="bibs/temo.html", target="_blank">BibTex</a>]
       </td>
     </tr>
	    
      <tr>
       <td class="pub_td1">04<img src="./imgs/DFormer.PNG" class="papericon"></td>
       <td class="pub_td2"> Bowen Yin, <font color="goldenrod">Xuying Zhang</font>, Zhongyu Li, Li Liu, Ming-Ming Cheng, Qibin Hou<sup>✉</sup>
        <br><b>Rethinking RGBD Representation Learning for Semantic Segmentation</b>
        <br>International Conference on Learning Representations (ICLR), 2024
        <br>
        [<a href="https://arxiv.org/pdf/2309.09668.pdf" target="_blank">Paper</a>]  
        [<a href="https://github.com/VCIP-RGBD/DFormer" target="_blank">Code (<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/VCIP-RGBD/DFormer?label=%F0%9F%8C%9F%20Star&color=blue">)</a>]
	[<a href="bibs/dformer.html", target="_blank">BibTex</a>]
       </td>
     </tr>
	    
    <tr>
      <td class="pub_td1">03<img src="./imgs/DIFNet.png" class="papericon"></td>
      <td class="pub_td2"> 
        Mingrui Wu*, <font color="goldenrod">Xuying Zhang</font>*, Xiaoshuai Sun<sup>✉</sup>, Yiyi Zhou, Chao chen, Jiaxin Gu, Xing Sun, Rongrong Ji
        <br><b>DIFNet: Boosting Visual Information Flow for Image Captioning</b>
        <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022, CCF-A
        <br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_DIFNet_Boosting_Visual_Information_Flow_for_Image_Captioning_CVPR_2022_paper.pdf" target="_blank">Paper</a>] 
        [<a href="https://github.com/mrwu-mac/DIFNet" target="_blank">Code (<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/mrwu-mac/DIFNet?label=%F0%9F%8C%9F%20Star&color=blue">)</a>]
	[<a href="bibs/difnet.html", target="_blank">BibTex</a>]
      </td>
    </tr>

    <tr>
      <td class="pub_td1">02<img src="./imgs/RSTNet.png" class="papericon"></td>
      <td class="pub_td2"> 
        <font color="goldenrod">Xuying Zhang</font>, Xiaoshuai Sun<sup>✉</sup>, Yunpeng Luo, Jiayi Ji, Yiyi Zhou, Yongjian Wu, Feiyue Huang, Rongrong Ji
        <br><b>RSTNet: Captioning with Adaptive Attention on Visual and Non-Visual Words </b>
        <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, CCF-A
        <br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_RSTNet_Captioning_With_Adaptive_Attention_on_Visual_and_Non-Visual_Words_CVPR_2021_paper.pdf" target="_blank">Paper</a>]    
        [<a href="https://github.com/zhangxuying1004/RSTNet" target="_blank">Code (<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhangxuying1004/RSTNet?label=%F0%9F%8C%9F%20Star&color=blue">)</a>]
	[<a href="bibs/rstnet.html", target="_blank">BibTex</a>]
      </td>
    </tr>

    <tr>
      <td class="pub_td1">01<img src="./imgs/MSA.png" class="papericon"></td>
      <td class="pub_td2"> Xiaoshuai Sun <font color="goldenrod">(supervisor)</font>, <font color="goldenrod">Xuying Zhang</font>, Liujuan Cao<sup>✉</sup>, Yongjian Wu, Feiyue Huang, Rongrong Ji
        <br><b>Exploring Language Prior for Mode-Sensitive Visual Attention Modeling </b>
        <br>Proceedings of the 28th ACM International Conference on Multimedia (ACM MM 2020), CCF-A
        <br>
        [<a href="https://drive.google.com/file/d/1bzKWpMIF4FxxJzKxTIqhBrpCgpIP-lhb/view" target="_blank">Paper</a>]  
        [<a href="https://github.com/zhangxuying1004/MSA" target="_blank">Code (<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhangxuying1004/MSA?label=%F0%9F%8C%9F%20Star&color=blue">)</a>]
	[<a href="bibs/msa.html", target="_blank">BibTex</a>]
      </td>
    </tr>

    </tbody>
  </table>
	
  <!--      待发表论文		-->
  <h3>Preprint</h3>
  <table class="pub_table">
    <tbody> 	  
    <tr>
      <td class="pub_td1">03<img src="./imgs/AGLNet.png" class="papericon"></td>
      <td class="pub_td2"> 
	Zhennan Chen, <font color="goldenrod">Xuying Zhang</font>, Tian-Zhu Xiang, Ying Tai.
	<br><b>Adaptive Guidance Learning for Camouflaged Object Detection </b>
	<br>arXiv preprint arXiv:2405.02824 (Under Review)
	<br>
	[<a href="https://arxiv.org/pdf/2405.02824.pdf" target="_blank">Paper</a>]  
	[<a href="https://github.com/ZNan-Chen/AGLNet" target="_blank">Code (<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/ZNan-Chen/AGLNet?label=%F0%9F%8C%9F%20Star&color=blue">)</a>]
	[<a href="bibs/aglnet.html", target="_blank">BibTex</a>]
      </td>
    </tr>   
	    
      <tr>
       <td class="pub_td1">02<img src="./imgs/RefCOD.png" class="papericon"></td>
       <td class="pub_td2"> <font color="goldenrod">Xuying Zhang</font>*, Bowen Yin*, Zheng Lin, Qibin Hou<sup>✉</sup>, Dengping Fan, Ming-Ming Cheng
        <br><b>Referring Camouflaged Object Detection</b>
        <br>arXiv preprint arXiv:2306.07532 (Under Review)
        <br>
        [<a href="https://arxiv.org/pdf/2306.07532.pdf" target="_blank">Paper</a>]  
        [<a href="https://github.com/zhangxuying1004/RefCOD" target="_blank">Code (<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhangxuying1004/RefCOD?label=%F0%9F%8C%9F%20Star&color=blue">)</a>]
	[<a href="bibs/refcod.html", target="_blank">BibTex</a>]
       </td>
     </tr>
	    
 	  
	  
    </tbody>
  </table>
  <!--      期刊论文		-->
  <h3>Journal</h3>
  <table class="pub_table">
    <tbody>  
     <tr>
      <td class="pub_td1">01<img src="./imgs/CamoFormer.png" class="papericon"></td>
      <td class="pub_td2"> Bochun Wang*, <font color="goldenrod">Xuanyu Yi</font>*, Jiandong Gao, Yanru Li, Wen Xu, Ji Wu, Demin Han    
        <br><b>Real-time prediction of upcoming respiratory events via machine learning using snoring sound signal </b>
        <br>Journal of Clinical Sleep Medicine
        <br>
        [<a href="https://jcsm.aasm.org/doi/pdf/10.5664/jcsm.9292" target="_blank">Paper</a>]  

      </td>
    </tr>	 

   
           
    </tbody>
  </table>

     </tbody>
  </table>
  <!--      专利		-->
  <h3>Patent</h3>
  <table class="pub_table">
    <tbody>  

        <br><b> A Real-Time Predictive Method for Sleep Apnea and Hypoventilation Based on Snoring </b>
       <br> Chinese Patent No.[CN202110620741.X], granted [2021-08-24].

      </td>
    </tr>	 

    </tbody>
  </table>
	
  <!--      专业活动		-->
  <h2>Professional Activities<a name="activities"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <ul>
    <li>Conference Reviewer 
	 <ul style="list-style-type:circle">
             <li> IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2023, 2024. </li>
	     <li> European Conference on Computer Vision (ECCV), 2022, 2024. </li>
                    <li> IEEE International Conference on Computer Vision (ICCV), 2023. </li>
         </ul>
    </li>

 
  </ul>

  <!--      荣誉奖项		-->
  <h2>Honors & Awards<a name="awards"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <ul>
    <li>  Excellent Graduate, Xiamen University, 2022 </li>
    <li>  National Scholarship, The Chinese Ministry of Education, 2021.  </li> 
    <li>  National Scholarship, The Chinese Ministry of Education, 2020.  </li> 
    <li>  Excellent Graduation Thesis, Hebei University of Technology, 2019.  </li>
    <li>  National Second Prize, Contemporary Undergraduate Mathematical Contest in Modeling, 2017.  </li> 
    <li>  Second Prize, Tianjin College Student Mathematics Competition, 2016.  </li> 
  </ul>


  <!--      足迹统计		-->
  <div id="footer">
    <div id="footer-text"></div>
  </div>
  © Xuanyu Yi

  <div class="container">
    <div style="display:inline-block;width:200px;">
      <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=wB8EwCw5zMQ5s3O964RSaWQ3U2o92gDHThri1tyf8Pc&cl=ffffff&w=a"></script>
    </div>
  </div>


  </div>
</body>

</html>
