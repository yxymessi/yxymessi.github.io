<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Xuanyu Yi - 易炫宇的个人网站">
  <meta name="keywords" content="易炫宇, Xuanyu Yi" />
  
  <link href="./imgs/tlzdoc.css" rel="stylesheet" type="text/css">
</head>
<body>
  <div id="layout-content" style="margin-top: 25px;">
  
  <table>
    <tbody>
      <tr>
	<!--      基本信息		-->
        <td width="670">
          <div id="toptitle">
            <h1>Xuanyu Yi &nbsp; 易炫宇</h1>
          </div>
	  <h3>Ph.D. Candidate @ <a href="https://www.ntu.edu.sg/" target="_blank">Nanyang Technological University</a></h3>
	  <p>
                Address: 50 Nanyang Ave, 639798, Singapore <br>
                Email: xuanyu001@e.ntu.edu.sg or xuanyucver@gmail.com<br>
          </p>
	  <h3 style="padding-top:-5px"></h3>
          <!--      google  scholar		-->
	  <img src="./assets/googlescholar.png" width="16" height="16" style="margin-bottom:-3px">
          <a href="https://scholar.google.com/citations?user=91i3wqgAAAAJ&hl=zh-CN#">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <!--      semantic scholar		-->
	  <img src="./assets/semanticscholar.png" width="17" height="17" style="margin-bottom:-3px">
          <a href="https://www.semanticscholar.org/author/Xuanyu-Yi/2072766550">Semantic Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          <!--      cv		-->
	  <img src="./assets/cv.png" width="15" height="15" style="margin-bottom:-3px">
          <a href="https://drive.google.com/file/d/19qlTnWOSzJQlheIphkyIFv4-3_-CFf06/view?usp=sharing">CV</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <!--      github		-->
	  <img src="./assets/github.jpg" width="16" height="16" style="margin-bottom:-3px">
          <a href="https://github.com/yxymessi">Github</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</td>
	<!--      头像		-->      
	<td>
          <img src="./imgs/xuanyu.JPG" border="0" width="190">
        </td>
      </tr>    
    </tbody>
  </table>
	  
  <!--      个人简介		-->
  <h2>Biography<a name="biography"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <p style="text-indent:2em;"> 
    I am currently a Ph.D. candidate in <a href="https://mreallab.github.io/index.html#experience" target="_blank">MreaL lab</a> @ NTU, advised by <a href="https://personal.ntu.edu.sg/hanwangzhang/" target="_blank">Prof. Hanwang Zhang</a>. I am also served as a research scholar in <a href="https://www.a-star.edu.sg/i2r" target="_blank">I<sup>2</sup>R, A<sup>*</sup>STAR</a>, advised by <a href="https://www.a-star.edu.sg/i2r/about-i2r/i2r-management/lim-joo-hwee" target="_blank">Prof. Lim Joo Hwee</a> . Before that, I received my Bachelor's degree from <a href="https://www.tsinghua.edu.cn/en/" target="_blank">Tsinghua University</a>, supervised by <a href="http://web.ee.tsinghua.edu.cn/wuji/zh_CN/index.htm" target="_blank">Prof. Ji Wu </a> and closely collabrated with <a href="http://www.slrss.cn/sourcedb_slrss_cas/kydw/ys/202008/t20200820_575915.html" target="_blank">Prof. Yirong Wu</a> and <a href="https://www.bjent.org/Html/Doctors/Main/Index_196.html" target="_blank">Prof. Demin Han</a>. The outline of my experience is as follows:
  </p>
  <ul>  
     <li> 01/2024 -- Present: Research Intern, <a href="https://www.kunlun.com/research/" target="_blank">2050 Research, Skywork AI</a>, Singapore. </li>
    <li> 08/2023 -- 12/2023: Research Intern, <a href="https://sail.sea.com/" target="_blank">SEA AI Lab</a>, Singapore. </li> 
       <li> 09/2021 -- Present: Ph.D. Student in Computer Science, <a href="https://www.ntu.edu.sg/" target="_blank">Nanyang Technological University</a>, Singapore. </li> 
    <li> 06/2020 -- 11/2020: B.S. in Computer Science, Exchange Program @ <a href="https://www.usc.edu/" target="_blank">University of Southern California</a>,  Los Angeles, America. </li>
    <li> 08/2017 -- 07/2021: B.S. in Electronic Engineering, <a href="https://www.tsinghua.edu.cn/en/" target="_blank">Tsinghua University</a>, Beijng, China. </li>
  </ul>
  <!--	  
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  -->
  </p>
  <p style="text-indent:2em;">

  <br/>

	  
    My research interests include representation learning, generative model, multi-modal LLM and 3D Vision. I believe that a true picture of nature is essentially a solution to Maxwell's equations. A perfect world model is actually a <i>numerical simulation</i> of various physical laws, such as electromagnetism and dynamics, etc. More recently, I focus on the following aspects:
    <ul> 
	 <li> MLLM debiased learning and reasoning. </li>  
	 <li> 3D understanding, reconstruction, generation, editting and simulation. </li> 
         <li> 3DGS-based or physics-based video generation model. </li> 
         <li> Anything about world model. </li> 
	 <li> Spatial-aware LLM or VLM. </li> 
	 
    </ul> 
     &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<b><font color="red">I’m graduating around Jul. 2025 and open to employment opportunities for a Research Scientist/Engineer position starting from 2025 summer in Singapore, Europe or China</b>.</font>
  </p>
  <!--      最新讯息		-->
  <h2>Latest News<a name="news"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <ul> 
    <li> 07/2024: Two paper were accepted by ECCV 2024. </li>
    <li> 02/2024: Two paper were accepted by CVPR 2024. </li>
    <li> 09/2023: One paper was accepted by ICCV 2023. </li>  
    <li> 10/2022: One paper was accepted by ECCV 2022 as <b>oral</b> presentation. </li>
  </ul>

  <!--      学术产出		-->
  <h2>Publication<a name="publications"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>

	  

	

  <!--      会议论文		-->
  <h3>Conference</h3>
  <table class="pub_table">
    <tbody>
      <tr>
       <td class="pub_td1">06<img src="./imgs/vce.png" class="papericon"></td>
       <td class="pub_td2"> Yuxuan Wang, <font color="goldenrod">Xuanyu Yi</font>, Zike Wu, Na Zhao, Long Chen, Hanwang Zhang
        <br><b>View-Consistent 3D Editing with Gaussian Splatting</b>
        <br>European Conference on Computer Vision (ECCV), 2024
        <br>
        [<a href="https://arxiv.org/abs/2403.11868" target="_blank">Paper</a>]  
        [<a href="https://github.com/SkyworkAI/" target="_blank">Code Coming]
       </td>
     </tr>
	    
      <tr>
       <td class="pub_td1">05<img src="./imgs/ar.png" class="papericon"></td>
       <td class="pub_td2"> Qingshan Xu, <font color="goldenrod">Xuanyu Yi</font>, Jianyao Xu, Wenbing Tao, Yew-Soon Ong, Hanwang Zhang
        <br><b>Few-shot NeRF by Adaptive Rendering Loss Regularization</b>
        <br>European Conference on Computer Vision (ECCV), 2024
        <br>
        [<a href="https://arxiv.org/" target="_blank">Paper Coming</a>]  
        [<a href="https://github.com/SkyworkAI/" target="_blank">Code Coming]
       </td>
     </tr>
	    
      <tr>
       <td class="pub_td1">04<img src="./imgs/dtc.png" class="papericon"></td>
       <td class="pub_td2"> <font color="goldenrod">Xuanyu Yi</font>, Zike Wu, Qingshan Xu, Pan Zhou, Joo-Hwee Lim, Hanwang Zhang
        <br><b>Diffusion time-step curriculum for one image to 3d generation</b>
        <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024
        <br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yi_Diffusion_Time-step_Curriculum_for_One_Image_to_3D_Generation_CVPR_2024_paper.pdf" target="_blank">Paper</a>]  
        [<a href=" https:
//github.com/yxymessi/DTC123" target="_blank">Code]
       </td>
     </tr>
	    
    <tr>
      <td class="pub_td1">03<img src="./imgs/consistent3D.png" class="papericon"></td>
      <td class="pub_td2"> 
       Zike Wu, Pan Zhou, <font color="goldenrod">Xuanyu Yi</font>, Xiaoding Yuan, Hanwang Zhang
        <br><b>Consistent3d: Towards consistent high-fidelity text-to-3d generation with deterministic sampling prior</b>
        <br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024
        <br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_Consistent3D_Towards_Consistent_High-Fidelity_Text-to-3D_Generation_with_Deterministic_Sampling_Prior_CVPR_2024_paper.pdf" target="_blank">Paper</a>]  
        [<a href="https:
//github.com/sail-sg/Consistent3D" target="_blank">Code]
      </td>
    </tr>

    <tr>
      <td class="pub_td1">02<img src="./imgs/invjoint.png" class="papericon"></td>
      <td class="pub_td2"> 
       <font color="goldenrod">Xuanyu Yi</font>, Jiajun Deng, Qianru Sun, Xian-Sheng Hua, Joo-Hwee Lim, Hanwang Zhang
        <br><b>Invariant training 2d-3d joint hard samples for few-shot point cloud recognition</b>
        <br>IEEE/CVF International Conference on Computer Vision (ICCV), 2023
        <br>    
        [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.pdf" target="_blank">Paper</a>]  
        [<a href="https://github.com/yxymessi/InvJoint" target="_blank">Code]
      </td>
    </tr>

    <tr>
      <td class="pub_td1">01<img src="./imgs/h2e.png" class="papericon"></td>
      <td class="pub_td2"> <font color="goldenrod">Xuanyu Yi</font>, Kaihua Tang, Xian-Sheng Hua, Joo-Hwee Lim, Hanwang Zhang
        <br><b>Identifying hard noise in long-tailed sample distribution </b>
        <br>European Conference on Computer Vision (ECCV), 2022  <font color="red">[Oral Presentation, 2.7% acceptance rate]</font>
        <br>
        [<a href="https://arxiv.org/pdf/2207.13378" target="_blank">Paper</a>]  
        [<a href="https://github.com/yxymessi/H2E-Framework" target="_blank">Code]
      </td>
    </tr>

    </tbody>
  </table>
	
  <!--      待发表论文		-->
  <h3>Preprint</h3>
  <table class="pub_table">
    <tbody> 	  
    <tr>
      <td class="pub_td1">02<img src="./imgs/mvgamba.png" class="papericon"></td>
      <td class="pub_td2"> 
	<font color="goldenrod">Xuanyu Yi</font>*, Zike Wu*, Qiuhong Shen*, Qingshan Xu, Pan Zhou, Joo-Hwee Lim, Shuicheng Yan, Xinchao Wang, Hanwang Zhang
	<br><b>MVGamba: Unify 3D Content Generation as State Space Sequence Modeling </b>
	<br>arXiv preprint arXiv:2405.02824 (Under Review)
	<br>
	[<a href="https://arxiv.org/pdf/2406.06367" target="_blank">Paper</a>]  
	[<a href="https://github.com/SkyworkAI/" target="_blank">Code Coming]
      </td>
    </tr>   
	    
      <tr>
       <td class="pub_td1">01<img src="./imgs/gamba.png" class="papericon"></td>
       <td class="pub_td2"> Qiuhong Shen*, Zike Wu*, <font color="goldenrod">Xuanyu Yi</font>*, Pan Zhou, Hanwang Zhang, Shuicheng Yan, Xinchao Wang
        <br><b>Gamba: Marry gaussian splatting with mamba for single view 3d reconstruction</b>
        <br>arXiv preprint arXiv:2406.06367 (Under Review)
        <br>
        [<a href="https://arxiv.org/pdf/2403.18795" target="_blank">Paper</a>]  
        [<a href="https://github.com/SkyworkAI/Gamba" target="_blank">Code]
       </td>
     </tr>
	    
 	  
	  
    </tbody>
  </table>
  <!--      期刊论文		-->
  <h3>Journal</h3>
  <table class="pub_table">
    <tbody>  
     <tr>
      <td class="pub_td1">01<img src="./imgs/JCSM.png" class="papericon"></td>
      <td class="pub_td2"> Bochun Wang*, <font color="goldenrod">Xuanyu Yi</font>*, Jiandong Gao, Yanru Li, Wen Xu, Ji Wu, Demin Han    
        <br><b>Real-time prediction of upcoming respiratory events via machine learning using snoring sound signal </b>
        <br>Journal of Clinical Sleep Medicine
        <br>
        [<a href="https://jcsm.aasm.org/doi/pdf/10.5664/jcsm.9292" target="_blank">Paper</a>]  

      </td>
    </tr>	 

   
           
    </tbody>
  </table>

     </tbody>
  </table>
  <!--      专利		-->
  <h3>Patent</h3>
  <table class="pub_table">
    <tbody>  

        <br><b> A Real-Time Predictive Method for Sleep Apnea and Hypoventilation Based on Snoring </b>
       <br> Chinese Patent No.[CN202110620741.X], granted [2021-08-24].

      </td>
    </tr>	 

    </tbody>
  </table>
	
  <!--      专业活动		-->
  <h2>Professional Activities<a name="activities"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <ul>
    <li>Conference Reviewer 
	 <ul style="list-style-type:circle">
             <li> IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2023, 2024. </li>
	     <li> European Conference on Computer Vision (ECCV), 2022, 2024. </li>
        <li>Conference on Neural Information Processing Systems (NeurIPS), 2024. </li>
                    <li> AAAI Conference on Artificial Intelligence (AAAI), 2023. </li>
       <li> International Joint Conference on Artificial Intelligence (IJCAI), 2023. </li>
         </ul>
    </li>
    
        <li>Journal Reviewer 
	 <ul style="list-style-type:circle">
	     <li> IEEE Transactions on Multimedia </li>
                    
         </ul>
    </li>


 
  </ul>

  <!--      荣誉奖项		-->
  <h2>Honors & Awards<a name="awards"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <ul>
    <li>  A<sup>*</sup>STAR</a> Merit Award, 2022. </li>
    <li>  Singapore International Graduate Award, 2021.  </li> 
    <li>  Silver Prize, Tsinghua University Rural Education Support, 2018.  </li> 
    <li> Tang Junyuan Scholarship Award，2017. </li> 
    <li>  Tsinghua University Leading Talent Program，2017. </li> 
  </ul>


  <!--      足迹统计		-->
  <div id="footer">
    <div id="footer-text"></div>
  </div>
  © Xuanyu Yi

  <div class="container">
    <div style="display:inline-block;width:200px;">
      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=y__Kv-EwZtsXY03ulBPgEyU4ydLw1gA1SHULrXd88YI"></script>
    </div>
  </div>


  </div>
</body>

</html>
